{"backend_state":"init","connection_file":"/projects/39b268b1-0e75-4ebd-9cf2-691243b37f4a/.local/share/jupyter/runtime/kernel-13a0cdee-54df-4d2c-9b3b-80b13397f40f.json","kernel":"python3-ubuntu","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"05cdbd","input":"","pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"06dc18","input":"","pos":22,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"a1b0c7","input":"","pos":18,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"81ded3","input":"## SPLIT\nx_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.2)","pos":4,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"bdfbdc","input":"clf.best_params_","output":{"0":{"data":{"text/plain":"{'max_depth': 5, 'n_estimators': 100}"},"exec_count":14,"output_type":"execute_result"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"c11f74","input":"#XGboost\nparameters = {'n_estimators': [80,90, 100, 110, 120, 130], \"max_depth\": [3,4,5]}\nmodel = xg.XGBRegressor()\nclf = GridSearchCV(model, parameters)\nclf.fit(x_train, y_train)","output":{"0":{"data":{"text/plain":"GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n                                    callbacks=None, colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None,\n                                    early_stopping_rounds=None,\n                                    enable_categorical=False, eval_metric=None,\n                                    gamma=None, gpu_id=None, grow_policy=None,\n                                    importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=None, max_bin=None,\n                                    max_cat_to_onehot=None, max_delta_step=None,\n                                    max_depth=None, max_leaves=None,\n                                    min_child_weight=None, missing=nan,\n                                    monotone_constraints=None, n_estimators=100,\n                                    n_jobs=None, num_parallel_tree=None,\n                                    predictor=None, random_state=None,\n                                    reg_alpha=None, reg_lambda=None, ...),\n             param_grid={'max_depth': [3, 4, 5],\n                         'n_estimators': [80, 90, 100, 110, 120, 130]})"},"exec_count":15,"output_type":"execute_result"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"2b1d78","input":"df['Country'] = countries","pos":15,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"b0e48a","input":"fig = px.scatter( x = y_test, y = y_hat)\nfig","output":{"0":{"data":{"iframe":"f0d806499da4c5b6b8182c67ab02129d33a643de"},"exec_count":25,"output_type":"execute_result"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"a0e40e","input":"model = xg.XGBRegressor()\nmodel.fit(x_train, y_train)","output":{"0":{"data":{"text/plain":"XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n             reg_lambda=1, ...)"},"exec_count":29,"output_type":"execute_result"}},"pos":6,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"26299f","input":"pip install xgboost","output":{"0":{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: xgboost in /projects/39b268b1-0e75-4ebd-9cf2-691243b37f4a/.local/lib/python3.8/site-packages (1.6.1)\r\n"},"1":{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.22.3)\r\nRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.8.0)\r\n"},"2":{"name":"stdout","output_type":"stream","text":"Note: you may need to restart the kernel to use updated packages.\n"}},"pos":1,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"823e9a","input":"## PREDICT\ny_hat = model.predict(x_test)","pos":13,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"df1850","input":"## EVALUATE - MSE & MAE\nmse = mean_squared_error(y_hat, y_test)\nmae = mean_absolute_error(y_hat, y_test)\nprint(mse)\n# print(mae)\n\nfrom sklearn.metrics import r2_score\nr2_score(y_test, y_hat)","output":{"0":{"name":"stdout","output_type":"stream","text":"5.611792252765242e-05\n"},"1":{"data":{"text/plain":"0.9987288139009327"},"exec_count":31,"output_type":"execute_result"}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":45,"id":"0a55fd","input":"##Linear Regression\nmodel = LinearRegression()\nmodel.fit(x_train, y_train)","output":{"0":{"data":{"text/plain":"LinearRegression()"},"exec_count":45,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":58,"id":"4f0f7c","input":"##Grid Search CV - Hyperparameter tuning\nparameters = [{'max_depth':(range(3,5)), 'n_estimators': (range(100,160,10)), 'min_samples_split':(range(0,6))}]\nmodel = RandomForestRegressor()\nclf = GridSearchCV(model, parameters, scoring='neg_mean_squared_error')","pos":19,"type":"cell"}
{"cell_type":"code","exec_count":59,"id":"9e761e","input":"clf.fit(x_train,y_train)","output":{"0":{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning:\n\n\n120 fits failed out of a total of 360.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n    trees = Parallel(\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1043, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 1315, in fit\n    super().fit(\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 250, in fit\n    raise ValueError(\nValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n    trees = Parallel(\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1043, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 1315, in fit\n    super().fit(\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 250, in fit\n    raise ValueError(\nValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n\n\n/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n\nOne or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n         nan         nan         nan         nan         nan         nan\n -0.00103435 -0.00087818 -0.00120375 -0.00105541 -0.00132353 -0.00118427\n -0.00121811 -0.00116767 -0.00112145 -0.00100462 -0.00108421 -0.00092812\n -0.00087155 -0.00114041 -0.00111632 -0.00138626 -0.00113128 -0.00101982\n -0.00102262 -0.00100327 -0.00086833 -0.00104948 -0.00098062 -0.00096494\n         nan         nan         nan         nan         nan         nan\n         nan         nan         nan         nan         nan         nan\n -0.00104938 -0.00096033 -0.0008309  -0.00086732 -0.00094121 -0.00101287\n -0.00091722 -0.0010674  -0.00100894 -0.00103641 -0.00079745 -0.00093578\n -0.00095202 -0.00108071 -0.00105108 -0.00088793 -0.00082782 -0.00093387\n -0.00117053 -0.00111472 -0.00098864 -0.00086917 -0.00092526 -0.0010242 ]\n\n"},"1":{"data":{"text/plain":"GridSearchCV(estimator=RandomForestRegressor(),\n             param_grid=[{'max_depth': range(3, 5),\n                          'min_samples_split': range(0, 6),\n                          'n_estimators': range(100, 160, 10)}],\n             scoring='neg_mean_squared_error')"},"exec_count":59,"output_type":"execute_result"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"48f05b","input":"##Lasso Model\nmodel = Lasso(alpha = 0.0001)\nmodel.fit(x_train, y_train)","pos":8,"type":"cell"}
{"cell_type":"code","exec_count":61,"id":"6f4e40","input":"##Random Forest Regressor Model\n\nmodel = RandomForestRegressor(max_depth = 4, n_estimators = 140, min_samples_split = 3)\nmodel.fit(x_train, y_train)","output":{"0":{"data":{"text/plain":"RandomForestRegressor(max_depth=4, min_samples_split=3, n_estimators=140)"},"exec_count":61,"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"8109c5","input":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport plotly.express as px\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nimport xgboost as xg\nfrom sklearn.model_selection import GridSearchCV","pos":2,"type":"cell"}
{"cell_type":"code","exec_count":86,"id":"afbf0f","input":"##Elastic Net Model\nparameters = {'alpha': [0.00000001, 0.0000001, 0.000001,0.00001, 0.0001, 0.001, 0.01,0.1], \"fit_intercept\": [True, False], 'l1_ratio': [0.65 ,0.7, 0.75, 0.8, 0.85, 0.9], 'selection': ['random', 'cyclic']}\nmodel = linear_model.ElasticNet()\nclf = GridSearchCV(model, parameters)\nclf.fit(x_train, y_train)","output":{"0":{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e-02, tolerance: 1.606e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.199e-03, tolerance: 1.606e-03\n\n"},"1":{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.124e-03, tolerance: 1.698e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.721e-03, tolerance: 1.606e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.764e-02, tolerance: 2.063e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.912e-02, tolerance: 1.910e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e-02, tolerance: 2.284e-03\n\n"},"2":{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.071e-03, tolerance: 2.124e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.866e-03, tolerance: 2.063e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e-02, tolerance: 2.284e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e-02, tolerance: 2.026e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.785e-02, tolerance: 2.124e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.018e-02, tolerance: 2.063e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.654e-02, tolerance: 1.910e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.592e-02, tolerance: 2.284e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e-02, tolerance: 2.026e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.505e-02, tolerance: 2.124e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.515e-02, tolerance: 2.063e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.615e-02, tolerance: 1.910e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e-02, tolerance: 2.284e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.343e-02, tolerance: 2.026e-03\n\n"},"3":{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.673e-03, tolerance: 2.063e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e-02, tolerance: 1.910e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e-02, tolerance: 2.284e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.782e-02, tolerance: 2.026e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e-02, tolerance: 2.124e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e-03, tolerance: 2.063e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.949e-02, tolerance: 1.910e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e-02, tolerance: 2.284e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e-02, tolerance: 2.026e-03\n\n"},"4":{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.217e-03, tolerance: 2.063e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.253e-03, tolerance: 2.124e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.278e-03, tolerance: 1.910e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.527e-03, tolerance: 1.910e-03\n\n"},"5":{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.049e-03, tolerance: 2.063e-03\n\n/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n\nObjective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.120e-03, tolerance: 1.910e-03\n\n"},"6":{"data":{"text/plain":"GridSearchCV(estimator=ElasticNet(),\n             param_grid={'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n                                   0.01, 0.1],\n                         'fit_intercept': [True, False],\n                         'l1_ratio': [0.65, 0.7, 0.75, 0.8, 0.85, 0.9],\n                         'selection': ['random', 'cyclic']})"},"exec_count":86,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":87,"id":"c1871b","input":"clf.best_params_","output":{"0":{"data":{"text/plain":"{'alpha': 1e-08, 'fit_intercept': True, 'l1_ratio': 0.9, 'selection': 'random'}"},"exec_count":87,"output_type":"execute_result"}},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":88,"id":"a7f620","input":"model = linear_model.ElasticNet(alpha = 1e-08, fit_intercept = True, l1_ratio = 0.9, selection = 'random')\nmodel.fit(x_train, y_train)","output":{"0":{"data":{"text/plain":"ElasticNet(alpha=1e-08, l1_ratio=0.9, selection='random')"},"exec_count":88,"output_type":"execute_result"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"14e4ba","input":"df = pd.read_csv(\"../data/emissions_clean.csv\")\ncountries = df.pop('Country')\ntarget = df.pop('Greenhouse Gas Emissions')\ndf.info()","output":{"0":{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 816 entries, 0 to 815\nData columns (total 10 columns):\n #   Column                         Non-Null Count  Dtype  \n---  ------                         --------------  -----  \n 0   Year                           816 non-null    float64\n 1   Natural Gas Production         816 non-null    float64\n 2   Crude Oil Production           816 non-null    float64\n 3   Motor Gasoline Production      816 non-null    float64\n 4   Gas Oil/Diesel Oil Production  816 non-null    float64\n 5   Hard Coal Import               816 non-null    float64\n 6   Natural Gas Import             816 non-null    float64\n 7   Crude Oil Import               816 non-null    float64\n 8   Motor Gasoline Import          816 non-null    float64\n 9   Gas Oil/Diesel Oil Import      816 non-null    float64\ndtypes: float64(10)\nmemory usage: 63.9 KB\n"}},"pos":3,"type":"cell"}
{"cell_type":"markdown","id":"b7880a","input":"# Elastic Net:\n\nmodel = linear\\_model.ElasticNet\\(alpha = 1e\\-08, fit\\_intercept = True, l1\\_ratio = 0.9, selection = 'random'\\)\n\nMSE: 0.00038549801741167547\n\nR^2: 0.982699160385049\n\n","pos":0,"type":"cell"}
{"id":0,"time":1657720957373,"type":"user"}
{"last_load":1657811898511,"type":"file"}